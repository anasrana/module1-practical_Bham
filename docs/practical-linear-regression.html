<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Practical: Linear regression | Essentials of Mathematics and Statistics</title>
  <meta name="description" content="This contains practicals for the second week of module 1 (Essentials of Mathematics and Statistics)." />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Practical: Linear regression | Essentials of Mathematics and Statistics" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://anasrana.github.io/module1-practical_Bham/" />
  
  <meta property="og:description" content="This contains practicals for the second week of module 1 (Essentials of Mathematics and Statistics)." />
  <meta name="github-repo" content="anasrana/module1-practical_Bham" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Practical: Linear regression | Essentials of Mathematics and Statistics" />
  
  <meta name="twitter:description" content="This contains practicals for the second week of module 1 (Essentials of Mathematics and Statistics)." />
  

<meta name="author" content="Anas A Rana" />


<meta name="date" content="2019-10-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="model-answers-linear-regression.html"/>
<script src="assets/jquery-2.2.3/jquery.min.js"></script>
<link href="assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Essentials of Mathematics and Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i><b>1.1</b> Prerequisites</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#data-sets"><i class="fa fa-check"></i><b>1.2</b> Data sets</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html"><i class="fa fa-check"></i><b>2</b> Practical: Linear regression</a><ul>
<li class="chapter" data-level="2.1" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#data"><i class="fa fa-check"></i><b>2.1</b> Data</a></li>
<li class="chapter" data-level="2.2" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#simulating-data"><i class="fa fa-check"></i><b>2.2</b> Simulating data</a></li>
<li class="chapter" data-level="2.3" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#fitting-simple-linear-regression-model"><i class="fa fa-check"></i><b>2.3</b> Fitting simple linear regression model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#least-squared-estimation"><i class="fa fa-check"></i><b>2.3.1</b> Least squared estimation</a></li>
<li class="chapter" data-level="2.3.2" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>2.3.2</b> Maximum likelihood estimation</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#effect-of-variance"><i class="fa fa-check"></i><b>2.4</b> Effect of variance</a></li>
<li class="chapter" data-level="2.5" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#exercise"><i class="fa fa-check"></i><b>2.5</b> Exercise</a><ul>
<li class="chapter" data-level="2.5.1" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#part-i"><i class="fa fa-check"></i><b>2.5.1</b> Part I</a></li>
<li class="chapter" data-level="2.5.2" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#part-ii"><i class="fa fa-check"></i><b>2.5.2</b> Part II</a></li>
<li class="chapter" data-level="2.5.3" data-path="practical-linear-regression.html"><a href="practical-linear-regression.html#part-iii"><i class="fa fa-check"></i><b>2.5.3</b> Part III</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-answers-linear-regression.html"><a href="model-answers-linear-regression.html"><i class="fa fa-check"></i>Model answers: Linear regression</a><ul>
<li class="chapter" data-level="2.6" data-path="model-answers-linear-regression.html"><a href="model-answers-linear-regression.html#exercise-i"><i class="fa fa-check"></i><b>2.6</b> Exercise I</a></li>
<li class="chapter" data-level="2.7" data-path="model-answers-linear-regression.html"><a href="model-answers-linear-regression.html#exercise-ii"><i class="fa fa-check"></i><b>2.7</b> Exercise II</a><ul>
<li class="chapter" data-level="2.7.1" data-path="model-answers-linear-regression.html"><a href="model-answers-linear-regression.html#comparison-of-data"><i class="fa fa-check"></i><b>2.7.1</b> Comparison of data</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="model-answers-linear-regression.html"><a href="model-answers-linear-regression.html#exercise-ii-1"><i class="fa fa-check"></i><b>2.8</b> Exercise II</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html"><i class="fa fa-check"></i><b>3</b> Practical: Principal component analysis</a><ul>
<li class="chapter" data-level="3.1" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#data-1"><i class="fa fa-check"></i><b>3.1</b> Data</a></li>
<li class="chapter" data-level="3.2" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#introduction-1"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#exercise-i-1"><i class="fa fa-check"></i><b>3.3</b> Exercise I</a></li>
<li class="chapter" data-level="3.4" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#exercise-ii-2"><i class="fa fa-check"></i><b>3.4</b> Exercise II</a></li>
<li class="chapter" data-level="3.5" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#exercise-iii"><i class="fa fa-check"></i><b>3.5</b> Exercise III</a></li>
<li class="chapter" data-level="3.6" data-path="practical-principal-component-analysis.html"><a href="practical-principal-component-analysis.html#exercise-iv-single-cell-data"><i class="fa fa-check"></i><b>3.6</b> Exercise IV: Single cell data</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="practical-multiple-regression.html"><a href="practical-multiple-regression.html"><i class="fa fa-check"></i><b>4</b> Practical: Multiple regression</a><ul>
<li class="chapter" data-level="4.1" data-path="practical-multiple-regression.html"><a href="practical-multiple-regression.html#multiple-regression"><i class="fa fa-check"></i><b>4.1</b> Multiple regression</a></li>
<li class="chapter" data-level="4.2" data-path="practical-multiple-regression.html"><a href="practical-multiple-regression.html#categorical-covariates"><i class="fa fa-check"></i><b>4.2</b> Categorical covariates</a></li>
<li class="chapter" data-level="4.3" data-path="practical-multiple-regression.html"><a href="practical-multiple-regression.html#residuals"><i class="fa fa-check"></i><b>4.3</b> Residuals</a></li>
<li class="chapter" data-level="4.4" data-path="practical-multiple-regression.html"><a href="practical-multiple-regression.html#gradient-descent-algorithm"><i class="fa fa-check"></i><b>4.4</b> Gradient descent algorithm (+)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html"><i class="fa fa-check"></i><b>5</b> Practical: Generalised linear models</a><ul>
<li class="chapter" data-level="5.1" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#data-2"><i class="fa fa-check"></i><b>5.1</b> Data</a></li>
<li class="chapter" data-level="5.2" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#detecting-snp-associations"><i class="fa fa-check"></i><b>5.2</b> Detecting SNP associations</a></li>
<li class="chapter" data-level="5.3" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#gwas-and-logistic-regression"><i class="fa fa-check"></i><b>5.3</b> GWAS and logistic regression</a></li>
<li class="chapter" data-level="5.4" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#negative-binomial-and-poisson-regression"><i class="fa fa-check"></i><b>5.4</b> Negative binomial and Poisson regression</a><ul>
<li class="chapter" data-level="5.4.1" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#count-based-glms"><i class="fa fa-check"></i><b>5.4.1</b> Count-based GLMs</a></li>
<li class="chapter" data-level="5.4.2" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#fitting-a-glm"><i class="fa fa-check"></i><b>5.4.2</b> Fitting a GLM</a></li>
<li class="chapter" data-level="5.4.3" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#comparing-nested-models"><i class="fa fa-check"></i><b>5.4.3</b> Comparing nested models</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#negative-binomial-vs-poisson-glms"><i class="fa fa-check"></i><b>5.5</b> Negative-Binomial vs Poisson GLMs</a></li>
<li class="chapter" data-level="5.6" data-path="practical-generalised-linear-models.html"><a href="practical-generalised-linear-models.html#further-understanding-the-model-optional"><i class="fa fa-check"></i><b>5.6</b> Further understanding the model (<strong>OPTIONAL</strong>)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Essentials of Mathematics and Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-linear-regression" class="section level1">
<h1><span class="header-section-number">2</span> Practical: Linear regression</h1>
<p>In this practical you will go through some of the basics of linear modeling in <code>R</code> as well as simulating data. The practical contains the following elements:</p>
<ul>
<li>simulate linear regression model</li>
<li>investigate parameters</li>
<li>characterize prediction accuracy</li>
<li>correlation of real world data</li>
</ul>
<p>We will use <code>reshape2</code>, <code>ggplo2</code>, and <code>bbmle</code> packages. Run the following command to make sure they are installed and loaded</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="practical-linear-regression.html#cb1-1"></a><span class="kw">install.packages</span>(<span class="st">&quot;ggplot2&quot;</span>)</span>
<span id="cb1-2"><a href="practical-linear-regression.html#cb1-2"></a><span class="kw">install.packages</span>(<span class="st">&quot;reshape2&quot;</span>)</span>
<span id="cb1-3"><a href="practical-linear-regression.html#cb1-3"></a><span class="kw">install.packages</span>(<span class="st">&quot;bbmle&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="practical-linear-regression.html#cb2-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb2-2"><a href="practical-linear-regression.html#cb2-2"></a><span class="kw">library</span>(reshape2)</span>
<span id="cb2-3"><a href="practical-linear-regression.html#cb2-3"></a><span class="kw">library</span>(bbmle)</span></code></pre></div>
<pre><code>## Loading required package: stats4</code></pre>
<div id="data" class="section level2">
<h2><span class="header-section-number">2.1</span> Data</h2>
<p>For this practical you will require three datasets:</p>
<ul>
<li><code>stork.txt</code> (<a href="https://canvas.bham.ac.uk/files/8117073/download?download_frd=1">download</a>)</li>
<li><code>lr_data1.Rdata</code> (<a href="https://raw.github.com/anasrana/module1-practical_Bham/master/data/lr_data1.Rdata">download</a>)</li>
<li><code>lr_data2.Rdata</code> (<a href="https://raw.github.com/anasrana/module1-practical_Bham/master/data/lr_data2.Rdata">download</a>).</li>
</ul>
</div>
<div id="simulating-data" class="section level2">
<h2><span class="header-section-number">2.2</span> Simulating data</h2>
<p>You will simulate data based on the simple linear regression model:</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1\, x_i + \epsilon_i,
\]</span></p>
<p>where <span class="math inline">\((x_i, y_i)\)</span> represent the <span class="math inline">\(i\)</span>-th measurement pair with <span class="math inline">\(i = 1, \ldots, N\)</span>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are regression coefficients representing intercept and slope respectively. We assume the noise term <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2)\)</span> is normally distributed with zero mean and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>First we define the values of the parameters of linear regression <span class="math inline">\((\beta_0, \beta_1, \sigma^2)\)</span>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="practical-linear-regression.html#cb4-1"></a>b0 &lt;-<span class="st"> </span><span class="dv">10</span> <span class="co"># regression coefficient for intercept</span></span>
<span id="cb4-2"><a href="practical-linear-regression.html#cb4-2"></a>b1 &lt;-<span class="st"> </span><span class="dv">-8</span> <span class="co"># regression coefficient for slope</span></span>
<span id="cb4-3"><a href="practical-linear-regression.html#cb4-3"></a>sigma2 &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># noise variance</span></span></code></pre></div>
<p>In the next step we will simulate <span class="math inline">\(N = 100\)</span> covariates <span class="math inline">\(x_i\)</span> by randomly sampling from the standard normal distribution:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="practical-linear-regression.html#cb5-1"></a><span class="kw">set.seed</span>(<span class="dv">198</span>) <span class="co"># set a seed to ensure data is reproducible</span></span>
<span id="cb5-2"><a href="practical-linear-regression.html#cb5-2"></a>N &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co"># no of data points to simulate</span></span>
<span id="cb5-3"><a href="practical-linear-regression.html#cb5-3"></a>x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="co"># simulate covariate</span></span></code></pre></div>
<p>Next we simulate the error term:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="practical-linear-regression.html#cb6-1"></a><span class="co"># simulate the noise terms, rnorm requires the standard deviation</span></span>
<span id="cb6-2"><a href="practical-linear-regression.html#cb6-2"></a>e &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="kw">sqrt</span>(sigma2))</span></code></pre></div>
<p>Finally we have all the parameters and variables to simulate the response variable <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="practical-linear-regression.html#cb7-1"></a><span class="co"># compute (simulate) the response variable</span></span>
<span id="cb7-2"><a href="practical-linear-regression.html#cb7-2"></a>y =<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>e</span></code></pre></div>
<p>We will plot our data using <code>ggplot2</code> so the data need to be in a <code>data.frame</code> object:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="practical-linear-regression.html#cb8-1"></a><span class="co"># Set up the data point</span></span>
<span id="cb8-2"><a href="practical-linear-regression.html#cb8-2"></a>sim_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)</span>
<span id="cb8-3"><a href="practical-linear-regression.html#cb8-3"></a></span>
<span id="cb8-4"><a href="practical-linear-regression.html#cb8-4"></a><span class="co"># create a new scatter plot using ggplot2</span></span>
<span id="cb8-5"><a href="practical-linear-regression.html#cb8-5"></a><span class="kw">ggplot</span>(sim_data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb8-6"><a href="practical-linear-regression.html#cb8-6"></a><span class="st">  </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/sim-data-1.png" width="2100" /></p>
<p>We define the true data <code>y_true</code> to be the true linear relationship between the covariate and the response without the noise.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="practical-linear-regression.html#cb9-1"></a><span class="co"># Compute true y values</span></span>
<span id="cb9-2"><a href="practical-linear-regression.html#cb9-2"></a>y_true &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x</span>
<span id="cb9-3"><a href="practical-linear-regression.html#cb9-3"></a></span>
<span id="cb9-4"><a href="practical-linear-regression.html#cb9-4"></a><span class="co"># Add the data to the existing data frame</span></span>
<span id="cb9-5"><a href="practical-linear-regression.html#cb9-5"></a>sim_data<span class="op">$</span>y_true &lt;-<span class="st"> </span>y_true</span></code></pre></div>
<p>Now we will add the true values of <span class="math inline">\(y\)</span> to the scatter plot:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="practical-linear-regression.html#cb10-1"></a>lr_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(sim_data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb10-2"><a href="practical-linear-regression.html#cb10-2"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb10-3"><a href="practical-linear-regression.html#cb10-3"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_true), <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb10-4"><a href="practical-linear-regression.html#cb10-4"></a></span>
<span id="cb10-5"><a href="practical-linear-regression.html#cb10-5"></a><span class="kw">print</span>(lr_plot)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/scatter-true-1.png" width="2100" /></p>
</div>
<div id="fitting-simple-linear-regression-model" class="section level2">
<h2><span class="header-section-number">2.3</span> Fitting simple linear regression model</h2>
<div id="least-squared-estimation" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Least squared estimation</h3>
<p>Now that you have simulated data you can use it to regress <span class="math inline">\(y\)</span> on <span class="math inline">\(x\)</span>, since this is simulated data we know the parameters and can make a comparison. In <code>R</code> we can use the function <code>lm()</code> for this, by default it implements a least squares estimate:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="practical-linear-regression.html#cb11-1"></a><span class="co"># Use the lm function to fit the data</span></span>
<span id="cb11-2"><a href="practical-linear-regression.html#cb11-2"></a>ls_fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> sim_data)</span>
<span id="cb11-3"><a href="practical-linear-regression.html#cb11-3"></a></span>
<span id="cb11-4"><a href="practical-linear-regression.html#cb11-4"></a><span class="co"># Display a summary of fit</span></span>
<span id="cb11-5"><a href="practical-linear-regression.html#cb11-5"></a><span class="kw">summary</span>(ls_fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = sim_data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.69905 -0.41534  0.02851  0.41265  1.53651 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  9.95698    0.06701   148.6   &lt;2e-16 ***
## x           -7.94702    0.07417  -107.1   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6701 on 98 degrees of freedom
## Multiple R-squared:  0.9915, Adjusted R-squared:  0.9914 
## F-statistic: 1.148e+04 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The output for <code>lm()</code> is an object (in this case <code>ls_fit</code>) which contains multiple variables. To access them there are some built in functions, e.g.Â <code>coef()</code>, <code>residuals()</code>, and <code>fitted()</code>. We will explore these in turn:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="practical-linear-regression.html#cb13-1"></a><span class="co"># Extract coefficients as a named vector</span></span>
<span id="cb13-2"><a href="practical-linear-regression.html#cb13-2"></a>ls_coef &lt;-<span class="st"> </span><span class="kw">coef</span>(ls_fit)</span>
<span id="cb13-3"><a href="practical-linear-regression.html#cb13-3"></a></span>
<span id="cb13-4"><a href="practical-linear-regression.html#cb13-4"></a><span class="kw">print</span>(ls_coef)</span></code></pre></div>
<pre><code>## (Intercept)           x 
##    9.956981   -7.947016</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="practical-linear-regression.html#cb15-1"></a><span class="co"># Extract intercept and slope</span></span>
<span id="cb15-2"><a href="practical-linear-regression.html#cb15-2"></a>b0_hat &lt;-<span class="st"> </span>ls_coef[<span class="dv">1</span>] <span class="co"># alternative ls_fit$coefficients[1]</span></span>
<span id="cb15-3"><a href="practical-linear-regression.html#cb15-3"></a>b1_hat &lt;-<span class="st"> </span>ls_coef[<span class="dv">2</span>] <span class="co"># alternative ls_fit$coefficients[2]</span></span>
<span id="cb15-4"><a href="practical-linear-regression.html#cb15-4"></a></span>
<span id="cb15-5"><a href="practical-linear-regression.html#cb15-5"></a><span class="co"># Generate the predicted data based on estimated parameters</span></span>
<span id="cb15-6"><a href="practical-linear-regression.html#cb15-6"></a>y_hat &lt;-<span class="st"> </span>b0_hat <span class="op">+</span><span class="st"> </span>b1_hat <span class="op">*</span><span class="st"> </span>x</span>
<span id="cb15-7"><a href="practical-linear-regression.html#cb15-7"></a>sim_data<span class="op">$</span>y_hat &lt;-<span class="st"> </span>y_hat <span class="co"># add to the existing data frame</span></span>
<span id="cb15-8"><a href="practical-linear-regression.html#cb15-8"></a></span>
<span id="cb15-9"><a href="practical-linear-regression.html#cb15-9"></a><span class="co"># Create scatter plot and lines for the original and fitted</span></span>
<span id="cb15-10"><a href="practical-linear-regression.html#cb15-10"></a>lr_plot &lt;-<span class="st"> </span><span class="kw">ggplot</span>(sim_data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb15-11"><a href="practical-linear-regression.html#cb15-11"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb15-12"><a href="practical-linear-regression.html#cb15-12"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_true), <span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">size =</span> <span class="fl">1.3</span>) <span class="op">+</span></span>
<span id="cb15-13"><a href="practical-linear-regression.html#cb15-13"></a><span class="st">  </span><span class="co"># plot predicted relationship in blue</span></span>
<span id="cb15-14"><a href="practical-linear-regression.html#cb15-14"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_hat), <span class="dt">colour =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb15-15"><a href="practical-linear-regression.html#cb15-15"></a></span>
<span id="cb15-16"><a href="practical-linear-regression.html#cb15-16"></a><span class="co"># force Rstudio to display the plot</span></span>
<span id="cb15-17"><a href="practical-linear-regression.html#cb15-17"></a>  <span class="kw">print</span>(lr_plot)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/lm-fit-1.png" width="2100" /></p>
<p>The estimated parameters and the plot shows a good correspondence between fitted regression parameters and the true relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span>. We can check this by plotting the residuals, this data is stored as the <code>residuals</code> parameter in the <code>ls_fit</code> object.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="practical-linear-regression.html#cb16-1"></a><span class="co"># Residuals</span></span>
<span id="cb16-2"><a href="practical-linear-regression.html#cb16-2"></a>ls_residual &lt;-<span class="st"> </span><span class="kw">residuals</span>(ls_fit) <span class="co"># can also be accessed via ls_fit$residuals</span></span>
<span id="cb16-3"><a href="practical-linear-regression.html#cb16-3"></a></span>
<span id="cb16-4"><a href="practical-linear-regression.html#cb16-4"></a><span class="co"># scatter plot of residuals</span></span>
<span id="cb16-5"><a href="practical-linear-regression.html#cb16-5"></a><span class="kw">plot</span>(ls_residual)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/resid-scatter-1.png" width="2100" /></p>
<p>A better way of summarising the data is to visualise them as a histogram:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="practical-linear-regression.html#cb17-1"></a><span class="kw">hist</span>(ls_residual)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/resid_hist-1.png" width="2100" /></p>
<p>We expect the mean and variance of the residuals to be close to the level used to generate the data.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="practical-linear-regression.html#cb18-1"></a><span class="kw">print</span>(<span class="kw">mean</span>(ls_residual))</span></code></pre></div>
<pre><code>## [1] -7.157903e-18</code></pre>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="practical-linear-regression.html#cb20-1"></a><span class="kw">print</span>(<span class="kw">var</span>(ls_residual))</span></code></pre></div>
<pre><code>## [1] 0.4444955</code></pre>
<p>This is as expected since subtracting a good fit from the data leaves <span class="math inline">\(\epsilon\)</span> which has <span class="math inline">\(0\)</span> mean and <span class="math inline">\(0.5\)</span> variance.</p>
</div>
<div id="maximum-likelihood-estimation" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Maximum likelihood estimation</h3>
<p>Next you will look at maximum likelihood estimation based on the same data you simulated earlier. This is a bit more involved as it requires you to explicitly write the function you wish to minimise. The function we use is part of the <code>bbmle</code> package.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="practical-linear-regression.html#cb22-1"></a><span class="co"># Loading the required package</span></span>
<span id="cb22-2"><a href="practical-linear-regression.html#cb22-2"></a><span class="kw">library</span>(bbmle)</span>
<span id="cb22-3"><a href="practical-linear-regression.html#cb22-3"></a></span>
<span id="cb22-4"><a href="practical-linear-regression.html#cb22-4"></a><span class="co"># function that will be minimised. It takes as arguments all parameters</span></span>
<span id="cb22-5"><a href="practical-linear-regression.html#cb22-5"></a><span class="co"># Here we are helped by the way R works we don&#39;t have to explicitly pass x.</span></span>
<span id="cb22-6"><a href="practical-linear-regression.html#cb22-6"></a><span class="co"># The function will use the existing estimates in the environment</span></span>
<span id="cb22-7"><a href="practical-linear-regression.html#cb22-7"></a>mle_ll &lt;-<span class="st"> </span><span class="cf">function</span>(beta0, beta1, sigma) {</span>
<span id="cb22-8"><a href="practical-linear-regression.html#cb22-8"></a>  <span class="co"># first we predict the response variable based on the guess for our response</span></span>
<span id="cb22-9"><a href="practical-linear-regression.html#cb22-9"></a>  y_pred =<span class="st"> </span>beta0 <span class="op">+</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>x</span>
<span id="cb22-10"><a href="practical-linear-regression.html#cb22-10"></a></span>
<span id="cb22-11"><a href="practical-linear-regression.html#cb22-11"></a>  <span class="co"># next we calculate the normal distribution based on the predicted value</span></span>
<span id="cb22-12"><a href="practical-linear-regression.html#cb22-12"></a>  <span class="co"># the guess for sigma and return the log</span></span>
<span id="cb22-13"><a href="practical-linear-regression.html#cb22-13"></a>  log_lh &lt;-<span class="st"> </span><span class="kw">dnorm</span>(y, <span class="dt">mean =</span> y_pred, <span class="dt">sd =</span> sigma, <span class="dt">log =</span> <span class="ot">TRUE</span>)</span>
<span id="cb22-14"><a href="practical-linear-regression.html#cb22-14"></a></span>
<span id="cb22-15"><a href="practical-linear-regression.html#cb22-15"></a>  <span class="co">#  We returnr the negative sum of the log likelihood</span></span>
<span id="cb22-16"><a href="practical-linear-regression.html#cb22-16"></a>  <span class="kw">return</span>(<span class="op">-</span><span class="kw">sum</span>(log_lh))</span>
<span id="cb22-17"><a href="practical-linear-regression.html#cb22-17"></a>}</span>
<span id="cb22-18"><a href="practical-linear-regression.html#cb22-18"></a></span>
<span id="cb22-19"><a href="practical-linear-regression.html#cb22-19"></a><span class="co"># This is the function that actually performs the estimation</span></span>
<span id="cb22-20"><a href="practical-linear-regression.html#cb22-20"></a><span class="co"># The first variable here is the function we will use</span></span>
<span id="cb22-21"><a href="practical-linear-regression.html#cb22-21"></a><span class="co"># The second variable passed is a list of initial guesses of parameters</span></span>
<span id="cb22-22"><a href="practical-linear-regression.html#cb22-22"></a>mle_fit &lt;-<span class="st"> </span><span class="kw">mle2</span>(mle_ll, <span class="dt">start =</span> <span class="kw">list</span>(<span class="dt">beta0 =</span> <span class="dv">-1</span>, <span class="dt">beta1 =</span> <span class="dv">20</span>, <span class="dt">sigma =</span> <span class="dv">10</span>))</span>
<span id="cb22-23"><a href="practical-linear-regression.html#cb22-23"></a></span>
<span id="cb22-24"><a href="practical-linear-regression.html#cb22-24"></a><span class="co"># With the same summary function as above we can output a summary of the fit</span></span>
<span id="cb22-25"><a href="practical-linear-regression.html#cb22-25"></a><span class="kw">summary</span>(mle_fit)</span></code></pre></div>
<pre><code>## Maximum likelihood estimation
## 
## Call:
## mle2(minuslogl = mle_ll, start = list(beta0 = -1, beta1 = 20, 
##     sigma = 10))
## 
## Coefficients:
##        Estimate Std. Error  z value     Pr(z)    
## beta0  9.957019   0.066336  150.099 &lt; 2.2e-16 ***
## beta1 -7.947005   0.073426 -108.231 &lt; 2.2e-16 ***
## sigma  0.663347   0.046904   14.143 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## -2 log L: 201.7011</code></pre>
<p>The estimated parameters using the maximum likelihood are also a very good estimate of the true values.</p>
</div>
</div>
<div id="effect-of-variance" class="section level2">
<h2><span class="header-section-number">2.4</span> Effect of variance</h2>
<p>Now investigate the quality of the predictions further by simulating more data sets and seeing how the variance affects the quality of the fit as indicated by the mean-squared error (mse).</p>
<p>To start you will define some parameter for the simulations, the number of simulations to run for each variance, and the variance values to try.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="practical-linear-regression.html#cb24-1"></a><span class="co"># number of simulations for each noise level</span></span>
<span id="cb24-2"><a href="practical-linear-regression.html#cb24-2"></a>n_simulations &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb24-3"><a href="practical-linear-regression.html#cb24-3"></a></span>
<span id="cb24-4"><a href="practical-linear-regression.html#cb24-4"></a><span class="co"># A vector of noise levels to try</span></span>
<span id="cb24-5"><a href="practical-linear-regression.html#cb24-5"></a>sigma_v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.1</span>, <span class="fl">0.4</span>, <span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">4.0</span>, <span class="fl">6.0</span>, <span class="fl">8.0</span>)</span>
<span id="cb24-6"><a href="practical-linear-regression.html#cb24-6"></a>n_sigma &lt;-<span class="st"> </span><span class="kw">length</span>(sigma_v)</span>
<span id="cb24-7"><a href="practical-linear-regression.html#cb24-7"></a></span>
<span id="cb24-8"><a href="practical-linear-regression.html#cb24-8"></a><span class="co"># Create a matrix to store results</span></span>
<span id="cb24-9"><a href="practical-linear-regression.html#cb24-9"></a>mse_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> n_simulations, <span class="dt">ncol =</span> n_sigma)</span>
<span id="cb24-10"><a href="practical-linear-regression.html#cb24-10"></a></span>
<span id="cb24-11"><a href="practical-linear-regression.html#cb24-11"></a><span class="co"># name row and column</span></span>
<span id="cb24-12"><a href="practical-linear-regression.html#cb24-12"></a><span class="kw">rownames</span>(mse_matrix) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>n_simulations)</span>
<span id="cb24-13"><a href="practical-linear-regression.html#cb24-13"></a><span class="kw">colnames</span>(mse_matrix) &lt;-<span class="st"> </span>sigma_v</span></code></pre></div>
<p>Next we will write a nested <code>for</code> loop. The first loop will be over the variances and a second loop over the number of repeats. We will simulate the data, perform a fit with <code>lm()</code>. We can use the <code>fitted()</code> function on the resulting object to extract the fitted values <span class="math inline">\(\hat{y}\)</span> and use this to compute the mean-squared error from the true value <span class="math inline">\(y\)</span>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="practical-linear-regression.html#cb25-1"></a><span class="co"># loop over variance</span></span>
<span id="cb25-2"><a href="practical-linear-regression.html#cb25-2"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_sigma) {</span>
<span id="cb25-3"><a href="practical-linear-regression.html#cb25-3"></a>  sigma2 &lt;-<span class="st"> </span>sigma_v[i]</span>
<span id="cb25-4"><a href="practical-linear-regression.html#cb25-4"></a></span>
<span id="cb25-5"><a href="practical-linear-regression.html#cb25-5"></a>  <span class="co"># for each simulation</span></span>
<span id="cb25-6"><a href="practical-linear-regression.html#cb25-6"></a>  <span class="cf">for</span> (it <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_simulations) {</span>
<span id="cb25-7"><a href="practical-linear-regression.html#cb25-7"></a></span>
<span id="cb25-8"><a href="practical-linear-regression.html#cb25-8"></a>    <span class="co"># Simulate the data</span></span>
<span id="cb25-9"><a href="practical-linear-regression.html#cb25-9"></a>    x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)</span>
<span id="cb25-10"><a href="practical-linear-regression.html#cb25-10"></a>    e &lt;-<span class="st"> </span><span class="kw">rnorm</span>(N, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="kw">sqrt</span>(sigma2))</span>
<span id="cb25-11"><a href="practical-linear-regression.html#cb25-11"></a>    y &lt;-<span class="st"> </span>b0 <span class="op">+</span><span class="st"> </span>b1 <span class="op">*</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>e</span>
<span id="cb25-12"><a href="practical-linear-regression.html#cb25-12"></a></span>
<span id="cb25-13"><a href="practical-linear-regression.html#cb25-13"></a>    <span class="co"># set up a data frame and run lm()</span></span>
<span id="cb25-14"><a href="practical-linear-regression.html#cb25-14"></a>    sim_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)</span>
<span id="cb25-15"><a href="practical-linear-regression.html#cb25-15"></a>    lm_fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data =</span> sim_data)</span>
<span id="cb25-16"><a href="practical-linear-regression.html#cb25-16"></a></span>
<span id="cb25-17"><a href="practical-linear-regression.html#cb25-17"></a>    <span class="co"># compute the mean squared error between the fit and the actual y&#39;s</span></span>
<span id="cb25-18"><a href="practical-linear-regression.html#cb25-18"></a>    y_hat &lt;-<span class="st"> </span><span class="kw">fitted</span>(lm_fit)</span>
<span id="cb25-19"><a href="practical-linear-regression.html#cb25-19"></a>    mse_matrix[it, i] &lt;-<span class="st"> </span><span class="kw">mean</span>((y_hat <span class="op">-</span><span class="st"> </span>y)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb25-20"><a href="practical-linear-regression.html#cb25-20"></a></span>
<span id="cb25-21"><a href="practical-linear-regression.html#cb25-21"></a>  }</span>
<span id="cb25-22"><a href="practical-linear-regression.html#cb25-22"></a>}</span></code></pre></div>
<p>We created a matrix to store the mse values, but to plot them using <code>ggplot2</code> we have to convert them to a <code>data.frame</code>. This can be done using the <code>melt()</code> function form the <code>reshape2</code> library. We can compare the results using boxplots.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="practical-linear-regression.html#cb26-1"></a><span class="kw">library</span>(reshape2)</span>
<span id="cb26-2"><a href="practical-linear-regression.html#cb26-2"></a></span>
<span id="cb26-3"><a href="practical-linear-regression.html#cb26-3"></a><span class="co"># convert the matrix into a data frame for ggplot2</span></span>
<span id="cb26-4"><a href="practical-linear-regression.html#cb26-4"></a>mse_df &lt;-<span class="st"> </span><span class="kw">melt</span>(mse_matrix)</span>
<span id="cb26-5"><a href="practical-linear-regression.html#cb26-5"></a><span class="co"># rename the columns</span></span>
<span id="cb26-6"><a href="practical-linear-regression.html#cb26-6"></a><span class="kw">names</span>(mse_df) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Simulation&quot;</span>, <span class="st">&quot;variance&quot;</span>, <span class="st">&quot;MSE&quot;</span>)</span>
<span id="cb26-7"><a href="practical-linear-regression.html#cb26-7"></a></span>
<span id="cb26-8"><a href="practical-linear-regression.html#cb26-8"></a><span class="co"># now use a boxplot to look at the relationship between</span></span>
<span id="cb26-9"><a href="practical-linear-regression.html#cb26-9"></a><span class="co"># mean-squared prediction error and variance</span></span>
<span id="cb26-10"><a href="practical-linear-regression.html#cb26-10"></a>mse_plt &lt;-<span class="st"> </span><span class="kw">ggplot</span>(mse_df, <span class="kw">aes</span>(<span class="dt">x =</span> variance, <span class="dt">y =</span> MSE)) <span class="op">+</span></span>
<span id="cb26-11"><a href="practical-linear-regression.html#cb26-11"></a><span class="st">  </span><span class="kw">geom_boxplot</span>(<span class="kw">aes</span>(<span class="dt">group =</span> variance))</span>
<span id="cb26-12"><a href="practical-linear-regression.html#cb26-12"></a></span>
<span id="cb26-13"><a href="practical-linear-regression.html#cb26-13"></a><span class="kw">print</span>(mse_plt)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/effect-plot-1.png" width="3600" /></p>
<p>You can see that the variances of the mse and the value of the mse go up with increasing variance in the simulation.</p>
<p>What changes do you need to make to the above function to plot the accuracy of the estimated regression coefficients as a function of variance?</p>
</div>
<div id="exercise" class="section level2">
<h2><span class="header-section-number">2.5</span> Exercise</h2>
<div id="part-i" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Part I</h3>
<p>Read in the data in <code>stork.txt</code>, compute the correlation and comment on it.</p>
<p>The data represents <code>no of storks</code> (column 1) in Oldenburg Germany from <span class="math inline">\(1930 - 1939\)</span> and the number of people (column 2).</p>
</div>
<div id="part-ii" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Part II</h3>
<p>Fit a simple linear model to the two data sets supplied (<code>lr_data1.Rdata</code> and <code>lr_data2.Rdata</code>). In both files the <span class="math inline">\((x,y)\)</span> data is saved in two vectors, <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p>
<p>Download the data from Canvas, you can read it into <code>R</code> and plot it with the following commands:</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="practical-linear-regression.html#cb27-1"></a><span class="kw">load</span>(<span class="st">&quot;lr_data1.Rdata&quot;</span>)</span>
<span id="cb27-2"><a href="practical-linear-regression.html#cb27-2"></a><span class="kw">plot</span>(x, y)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/ex-1-1.png" width="2100" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="practical-linear-regression.html#cb28-1"></a><span class="kw">load</span>(<span class="st">&quot;lr_data2.Rdata&quot;</span>)</span>
<span id="cb28-2"><a href="practical-linear-regression.html#cb28-2"></a><span class="kw">plot</span>(x, y)</span></code></pre></div>
<p><img src="Practicals-module_1_files/figure-html/ex-1-2.png" width="2100" /></p>
<p>Fit the linear model and comment on the differences between the data.</p>
</div>
<div id="part-iii" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Part III</h3>
<p>Investigate how the sample size will affect the quality of the fit using mse, use the code for investigating the affect of variance as inspiration.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-answers-linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Practicals-module_1.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
